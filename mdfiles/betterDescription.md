# Better Description

Here I simply list some of good expressions or sentences in top-level English papers. Keeping in mind that **practice makes perfect**.

### 2018/04/01

- Then, we describe the state-of-the-art approach proposed by Sarkar et al., **henceforth referred to as** residual-based approach.

- In Figure 2, the **horizontal axis** represents the ..., whereas the **vertical axis** represents the ...

- As the configuration space often **explodes exponentially with** the number of configuration options, analyzing every individual system configuration becomes infeasible in real-world projects.

- The **t-wise** algorithm covers all combinations of any t configuration options. 

- When the cost of collecting data is higher than the cost of building a performance model, it's **imperative** to minimize the number of measurements required for model building.

- Learning curves typically have a **steep sloping portion** early in the curve followed by a **plateau** late in the curve.

- When the counts of features selected and deselected is, **at least**, at a predefined threshold.

### 2018/04/02

- Our research questions **are geared towards finding** optional configurations when building an accurate model of a given system is not possible.

- The number of measurements is **an order of magnitude** smaller than XXX approach.

- Thus, any performance prediction model built for this purpose should be evaluated **not only** in terms of prediction accuracy, **but also** in terms of measurement cost involved in building the training and testing sets.

- This is a critical step that needs to be performed in every iteration and to check whether the built prediction model has **converged to** an acceptable accuracy.

- Projective sampling address this problem by **approximating the learning curve** using a minimal set of initial sample points.

- We search for a best-fit function that can **extrapolate** the remaining learning curve.

- The use of random sampling in those works **was motivated by the idea that** in practice, available measured configurations of a system might not follow any particular feature-coverage criteria and would be **essentially** random.

### 2018/04/04

- Three candidate configuration options, a, b, and c, **constitute** a search space of eight combinations.

- An **off-the-shelf** tool of pairwise follows the predefined rule and cannot cover all possible configurations.

### 2018/04/05

- Our results show that building performance-influence model is (a) **computationally tractable**, (b) our approach finds actual influences and represents them directly, and (c) we **attain** a reasonable prediction accuracy.

### 2018/04/06

- Since it is infeasible to run all **(2^n)** configurations for a system with **n** features, the key challenge is to accurately predict the performance of the system on all configurations by measuring only a small number of sample configurations, as is **being actively studied** in many recent works [1,2,3,4,5,6].

### 2018/04/07

- Process Automation **per se** is an old idea, going back to the pioneering work of Osterweil [1].

### 2018/04/12

- Even such a simple case with only 16 features **gives rise to** 1,152 configurations.

- Software engineers often **make poor choices** about configuration or, **even worse**, they usually use a sub-optimal configuration production.

- Modern software systems come with **a daunting number of** configuration options.

- The configurations **are also referred to as** independent variables. The performance measure **is also referred to as** dependent variable.

### 2018/04/16

- **In the face of** hundreds of configuration options, it is difficult to keep track of the effects of individual configuration options and their mutual interactions. (in the face of = when we face)

- The figure shows that having a good configuration reduces the response time **by a factor of 40** when compared to the worst possible configuration. (by a factor of 40 = 40 times)

- Each element of a configuration represents a feature, which can either be True or False, based on whether the feature is selected or not.

### 2018/04/17

- The choice of the optimizer does not **critically effect** this conclusion.

### 2018/04/19

- Transfer leaning can only be useful **in cases where** the source environments is similar to the target environment.

- It must be noted that transfer learning methods **place an implicit faith** in the nature of the source.

- An incorrect choice of source may result in the all too common **negative transfer phenomenon**.

- A small difference in performance measure can lead to a large rank difference and **vice-versa**.
